{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate image to corresponding alphabhet using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pyttsx3;\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 50 #We'll be workign with 50 * 50 pixel images\n",
    "LABELS = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
    "LABELS.append(\"nothing\")\n",
    "LABELS.append(\"space\")\n",
    "engine = pyttsx3.init();\n",
    "engine.setProperty('rate', 105)\n",
    "engine.setProperty('voice', 0)\n",
    "MODEL_PATH = \"trained_model\\my_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"test.jpg\"\n",
    "\n",
    "def preprocess_image(IMG_PATH):\n",
    "    \"\"\"returns image array by preprocessing the image\n",
    "    Keyword arguments:\n",
    "    IMG_PATH: path of the image\n",
    "    Example: img_array = preprocess_image(\"a.jpg\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Load image with target size and convert img to array\n",
    "        img = image.load_img(IMG_PATH, target_size = (IMAGE_SIZE,IMAGE_SIZE))\n",
    "        plt.imshow(img)\n",
    "        img_array = image.img_to_array(img)\n",
    "       # imutils.resize(img,IMAGE_SIZE,IMAGE_SIZE)\n",
    "        #Change color sapce to gray\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Reshape array to l * w * channels\n",
    "        img_array = img_array.reshape(IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        \n",
    "        #Normalize th array\n",
    "        img_array /= 225.0\n",
    "        \n",
    "        #Expand Dimension of the array as our model expects a 4D array\n",
    "        img_array = np.expand_dims(img_array, axis = 0)\n",
    "        return img_array\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "\n",
    "def which_letter(IMG_PATH):\n",
    "    \"\"\"returns confident_percent, predicted label using the model or None if exception occurs\n",
    "    Keyword arguments:\n",
    "    IMG_PATH: path of the image\n",
    "    eg:\n",
    "        print(which_letter(\"sample.jpeg\"))\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_array = preprocess_image(IMG_PATH)\n",
    "        preds = model.predict(img_array)\n",
    "        most_likely_class_index = int(np.argmax(preds))\n",
    "        \n",
    "        np.set_printoptions(suppress = True, precision = 4)\n",
    "        preds *= 100\n",
    "        print(preds)\n",
    "        return preds.max(), LABELS[most_likely_class_index]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "confident_percent, predicted_label = which_letter(IMG_PATH)\n",
    "if confident_percent is not None:\n",
    "    print(\"The predicted letter is {} with confidence percentage {}%\".format(predicted_label, confident_percent))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(img_array):\n",
    "    \n",
    "    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    img_array = cv2.resize(img_array, (50, 50))\n",
    "    #Reshape array to l * w * channels\n",
    "    img_array = img_array.reshape(IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "\n",
    "    #Normalize th array\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    #Expand Dimension of the array as our model expects a 4D array\n",
    "    img_array = np.expand_dims(img_array, axis = 0)\n",
    "    return img_array\n",
    "\n",
    "def which(img_array):\n",
    "   \n",
    "    img_array = pre_process(img_array)\n",
    "    preds = model.predict(img_array)\n",
    "    most_likely_class_index = int(np.argmax(preds))\n",
    "    np.set_printoptions(suppress = True, precision = 4)\n",
    "    preds *= 100\n",
    "    #print(preds)\n",
    "    return preds.max(), LABELS[most_likely_class_index]\n",
    " \n",
    "\n",
    "img_array = cv2.imread(\"P_test.jpg\")\n",
    "percent, label = which(img_array)\n",
    "print(percent, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Frames from Webcam and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"ASL\"\n",
    "frame_height, frame_width, roi_height, roi_width = 480, 900, 600, 300\n",
    " \n",
    "def getMaxContour(contours, minArea = -1):\n",
    "    maxC = None\n",
    "    maxArea = minArea\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area > maxArea):\n",
    "            maxArea = area\n",
    "            maxC = cnt\n",
    "    return maxC\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)\n",
    "#cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "sentence = \"\"\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret is None:\n",
    "        print(\"No Frame Captured\")\n",
    "        continue\n",
    "        \n",
    "    #frame = cv2.resize(frame, (0, 0))\n",
    "    cv2.rectangle(frame,(0, 0),(roi_width, roi_height),(255,0,0), 3) # bounding box which captures ASL sign to be detected by the system\n",
    "    img1 = frame[0: roi_height, 0: roi_width]\n",
    "    \n",
    "    img_ycrcb = cv2.cvtColor(img1, cv2.COLOR_BGR2YCR_CB)\n",
    "    blur = cv2.GaussianBlur(img_ycrcb ,(11,11),0)\n",
    "    \n",
    "    #lower  and upper skin color\n",
    "    skin_ycrcb_min = np.array((0, 138, 67))\n",
    "    skin_ycrcb_max = np.array((255, 173, 133))\n",
    "    \n",
    "    mask = cv2.inRange(blur, skin_ycrcb_min, skin_ycrcb_max)  # detecting the hand in the bounding box using skin detection\n",
    "    \n",
    "    kernel = np.ones((2, 2), dtype = np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations = 1)\n",
    "    \n",
    "    _, contours, _ = cv2.findContours(mask.copy(),cv2.RETR_EXTERNAL, 2) \n",
    "    cnt= getMaxContour(contours, minArea = 2000)\n",
    "    naya = cv2.bitwise_and(img1, img1, mask = mask)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    \n",
    "    #Centre cropping the image\n",
    "    x_start, y_start, x_end, y_end = 0, 0, 0, 0\n",
    "    mx = 0\n",
    "    if w > 0 and h > 0:\n",
    "        mx = max(w, h, 150)\n",
    "        if x + 7 * mx // 8 > roi_width and y + mx > roi_height:\n",
    "            mx = max(roi_width - x, roi_height - y, 150)\n",
    "            x_start, x_end = roi_width - mx, roi_width\n",
    "            y_start, y_end = roi_height - mx, roi_height\n",
    "            \n",
    "        elif y + mx > roi_height and x == 0:\n",
    "            mx = max(w, roi_height - y, 150)\n",
    "            x_start, x_end = x, x + mx\n",
    "            y_start, y_end = roi_height - mx, roi_height\n",
    "        elif y + mx > roi_height:\n",
    "            mx = max(w, roi_height - y, 150)\n",
    "            x_start, x_end = x - mx // 8, x + 7 * mx // 8\n",
    "            y_start, y_end = roi_height - mx, roi_height\n",
    "        elif x + 7 * mx // 8 > roi_width:\n",
    "            mx = max(roi_width - x, h, 150)\n",
    "            x_start, x_end = roi_width - mx, roi_width\n",
    "            y_start, y_end = y, y + mx\n",
    "        elif x == 0:\n",
    "            x_start, x_end = 0, mx\n",
    "            y_start, y_end = y, y + mx\n",
    "        else:\n",
    "            x_start, x_end = x - mx // 8, x + 7 * mx // 8\n",
    "            y_start, y_end = y, y + mx\n",
    "        \n",
    "    \n",
    "    #Draw Green Square around the hand\n",
    "    cv2.rectangle(img1, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)      \n",
    "   \n",
    "\n",
    "    #cv2.imshow('img1', img1)\n",
    "    #cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"naya\", naya)\n",
    "    hand_bg_rm = naya[y_start: y_end, x_start: x_end]\n",
    "    hand = img1[y_start: y_end, x_start: x_end]\n",
    "    \n",
    "    #Control Key\n",
    "    c = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    #Speak the sentence\n",
    "    if len(sentence) > 0 and c == ord('s'):\n",
    "        engine.say(sentence)\n",
    "        engine.runAndWait() \n",
    "    \n",
    "    #If  valid hand area is cropped\n",
    "    if hand.shape[0] != 0 and hand.shape[1] != 0:\n",
    "        conf, label = which(hand)\n",
    "        conf, label1 = which(hand_bg_rm)\n",
    "        cv2.putText(frame, label,(50, 50),cv2.FONT_HERSHEY_COMPLEX_SMALL, .7,(0,0,255))\n",
    "        if c == ord('n'):\n",
    "            if label == \"nothing\":\n",
    "                pass\n",
    "            elif label == \"space\":\n",
    "                sentence += \" \"\n",
    "            else:\n",
    "                sentence += label\n",
    "        \n",
    "        #Clear the sentence\n",
    "        if c == ord('c'):\n",
    "            sentence = \"\"\n",
    "        \n",
    "        #Delete the last character\n",
    "        if c == ord('d'):\n",
    "            sentence = sentence[:-1]\n",
    "       \n",
    "            \n",
    "    cv2.putText(frame, sentence, (50, 70), cv2.FONT_HERSHEY_COMPLEX_SMALL, .7, (0, 0, 255))\n",
    "    cv2.imshow(window_name,frame)\n",
    "    \n",
    "    if c == 32:\n",
    "        if hand.shape[0] == hand.shape[1] + 1:\n",
    "            hand =  img1[y_start: y_end, x_start: x_end + 1]\n",
    "        elif hand.shape[1] == hand.shape[0] + 1:\n",
    "             hand =  img1[y_start: y_end + 1, x_start: x_end]            \n",
    "        elif hand.shape[0] != hand.shape[1]:\n",
    "            print(hand.shape)\n",
    "            print(\"Outside ROI\")\n",
    "            continue\n",
    "        cv2.imwrite(\"test.jpg\", hand)\n",
    "        cv2.imwrite(\"test_bg_less.jpg\", hand_bg_rm)\n",
    "    if c == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DOS\n",
    "1. Fixing holes in masked image(Reducing ROI)\n",
    "2. Creating and training datasets\n",
    "3. translate letter to sentence and speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
